{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('status_changes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['contact_email'], inplace=True)\n",
    "data['contact_email'] = data['contact_email'].str.split(',', expand=True, n=1)[0]\n",
    "data['contact_email'] = data['contact_email'].str.split(';', expand=True, n=1)[0]\n",
    "data['contact_email'] = data['contact_email'].str.lower()\n",
    "data.drop_duplicates(subset=['contact_email'], inplace=True)\n",
    "data[['username','hostname']] = data['contact_email'].str.lower().str.split('@', expand=True, n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = data['group_concat(status_to)'].str.split(',')\n",
    "# check if the user has ever been a paying customer by checking if it was in 17 or 2\n",
    "data['free_trial'] = split.apply(lambda x: '17' in x or '2' in x)\n",
    "\n",
    "data.replace({True: 1, False: 0}, inplace=True)\n",
    "data.drop(columns=['group_concat(status_to)'], inplace=True)\n",
    "data.drop(columns=['contact_email'], inplace=True)\n",
    "\n",
    "del split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after reviewing the data it is fine to truncate it to 23 characters for sanity\n",
    "data['username'] = data['username'].str[:23]\n",
    "data['hostname'] = data['hostname'].str[:23]\n",
    "\n",
    "# One hot encode the username by mapping each character to the alphabet and special characters as 0 and numbers as 27\n",
    "data['username_encoded'] = data['username'].apply(lambda x: [ord(char) - 96 if char.isalpha() else 27 if char.isnumeric() else 0 for char in str(x)])\n",
    "data['hostname_encoded'] = data['hostname'].apply(lambda x: [ord(char) - 96 if char.isalpha() else 27 if char.isnumeric() else 0 for char in str(x)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "data_length = len(data)\n",
    "\n",
    "# transform the categorical column lists into columns of their own\n",
    "hostname_columns = pd.DataFrame(X['hostname_encoded'].values.tolist(), columns=['hostname_encoded_1', 'hostname_encoded_2', 'hostname_encoded_3', 'hostname_encoded_4', 'hostname_encoded_5', 'hostname_encoded_6', 'hostname_encoded_7', 'hostname_encoded_8', 'hostname_encoded_9', 'hostname_encoded_10', 'hostname_encoded_11', 'hostname_encoded_12', 'hostname_encoded_13', 'hostname_encoded_14', 'hostname_encoded_15', 'hostname_encoded_16', 'hostname_encoded_17', 'hostname_encoded_18', 'hostname_encoded_19', 'hostname_encoded_20', 'hostname_encoded_21', 'hostname_encoded_22', 'hostname_encoded_23'])\n",
    "username_columns = pd.DataFrame(X['username_encoded'].values.tolist(), columns=['username_encoded_1', 'username_encoded_2', 'username_encoded_3', 'username_encoded_4', 'username_encoded_5', 'username_encoded_6', 'username_encoded_7', 'username_encoded_8', 'username_encoded_9', 'username_encoded_10', 'username_encoded_11', 'username_encoded_12', 'username_encoded_13', 'username_encoded_14', 'username_encoded_15', 'username_encoded_16', 'username_encoded_17', 'username_encoded_18', 'username_encoded_19', 'username_encoded_20', 'username_encoded_21', 'username_encoded_22', 'username_encoded_23'])\n",
    "\n",
    "# merge all the columns together\n",
    "X = pd.concat([hostname_columns, username_columns], axis=1)\n",
    "X.replace({np.nan: 0}, inplace=True)\n",
    "y = data['free_trial']\n",
    "\n",
    "assert len(X) == data_length\n",
    "\n",
    "del data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hostname_columns\n",
    "del username_columns\n",
    "\n",
    "# scale the data# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "del scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=46, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    " \n",
    "log_dir = f\"./logs/{time.time()}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=False)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[tensorboard])\n",
    "\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prediction'] = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the global statistics for data[]['prediction'] and format it to 2 decimal places\n",
    "print(f\"Global Prediction: {data['prediction'].mean():.2f}\")\n",
    "\n",
    "# create a new dataframe with the statistics per hostname and order by the count of hostname\n",
    "stats = data.groupby(['hostname']).agg({'prediction': ['mean', 'count']})\n",
    "stats.columns = ['prediction_mean', 'count']\n",
    "stats.sort_values(by=['count'], ascending=False, inplace=True)\n",
    "\n",
    "print(stats.head(20).to_string(formatters={'prediction_mean': '{:.2f}'.format}))\n",
    "print(stats.tail(20).to_string(formatters={'prediction_mean': '{:.2f}'.format}))\n",
    "\n",
    "# create a subset of the dataframe with the top 100 hostnames\n",
    "top_100 = stats.head(100).copy()\n",
    "# sort by prediction_mean\n",
    "top_100.sort_values(by=['prediction_mean'], ascending=False, inplace=True)\n",
    "# print the top 10 hostnames and format the prediction_mean to 2 decimal places\n",
    "print(top_100.head(20).to_string(formatters={'prediction_mean': '{:.2f}'.format}))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
