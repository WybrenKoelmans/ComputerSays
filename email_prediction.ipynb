{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('status_changes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['contact_email'] = data['contact_email'].str.split(',', expand=True, n=1)[0].str.lower()\n",
    "data.drop_duplicates(inplace=True)\n",
    "data[['username','hostname']] = data['contact_email'].str.lower().str.split('@', expand=True, n=1)\n",
    "data[['domain', 'tld']] = data['hostname'].str.split('.', expand=True, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = data['group_concat(status_to)'].str.split(',')\n",
    "data['free_trial'] = split.apply(lambda x: '17' in x)\n",
    "data['client'] = split.apply(lambda x: '2' in x)\n",
    "domain_freqs = data['hostname'].value_counts()\n",
    "username_freqs = data['username'].value_counts()\n",
    "data['hostname_unique'] = data['hostname'].map(domain_freqs) < 10\n",
    "data['hostname_length'] = data['hostname'].str.len()\n",
    "data['username_unique'] = data['username'].map(username_freqs) < 10\n",
    "data['username_length'] = data['username'].str.len()\n",
    "#data['username_non_alpha'] = data['username'].apply(lambda x: sum(1 for char in str(x) if not char.isalnum()))\n",
    "\n",
    "data.replace({True: 1, False: 0}, inplace=True)\n",
    "\n",
    "del split\n",
    "del domain_freqs\n",
    "del username_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the username by mapping each character to the alphabet and special characters as 30\n",
    "data['username_encoded'] = data['username'].apply(lambda x: [ord(char) - 96 if char.isalpha() else 30 for char in str(x)])\n",
    "\n",
    "# One hot encode the hostname by mapping each character to the alphabet and special characters as 30\n",
    "data['hostname_encoded'] = data['hostname'].apply(lambda x: [ord(char) - 96 if char.isalpha() else 30 for char in str(x)])\n",
    "\n",
    "# One hot encode the tld by mapping each character to the alphabet and special characters as 30\n",
    "data['tld_encoded'] = data['tld'].apply(lambda x: [ord(char) - 96 if char.isalpha() else 30 for char in str(x)])\n",
    "\n",
    "# make sure all lists are the same length and not longer than 20\n",
    "data['username_encoded'] = data['username_encoded'].apply(lambda x: x[:20] + [0]*(20-len(x)))\n",
    "data['hostname_encoded'] = data['hostname_encoded'].apply(lambda x: x[:20] + [0]*(20-len(x)))\n",
    "\n",
    "# make sure the tld is exactly 3 characters long\n",
    "data['tld_encoded'] = data['tld_encoded'].apply(lambda x: x[:3] + [0]*(3-len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_columns = X.drop(['hostname_encoded', 'username_encoded', 'tld_encoded'], axis=1)\n",
    "categorical_columns = X[['hostname_encoded', 'username_encoded', 'tld_encoded']]\n",
    "\n",
    "# transform the categorical column lists into columns of their own\n",
    "hostname_columns = pd.DataFrame(categorical_columns['hostname_encoded'].values.tolist(), columns=['hostname_encoded_1', 'hostname_encoded_2', 'hostname_encoded_3', 'hostname_encoded_4', 'hostname_encoded_5', 'hostname_encoded_6', 'hostname_encoded_7', 'hostname_encoded_8', 'hostname_encoded_9', 'hostname_encoded_10', 'hostname_encoded_11', 'hostname_encoded_12', 'hostname_encoded_13', 'hostname_encoded_14', 'hostname_encoded_15', 'hostname_encoded_16', 'hostname_encoded_17', 'hostname_encoded_18', 'hostname_encoded_19', 'hostname_encoded_20'])\n",
    "username_columns = pd.DataFrame(categorical_columns['username_encoded'].values.tolist(), columns=['username_encoded_1', 'username_encoded_2', 'username_encoded_3', 'username_encoded_4', 'username_encoded_5', 'username_encoded_6', 'username_encoded_7', 'username_encoded_8', 'username_encoded_9', 'username_encoded_10', 'username_encoded_11', 'username_encoded_12', 'username_encoded_13', 'username_encoded_14', 'username_encoded_15', 'username_encoded_16', 'username_encoded_17', 'username_encoded_18', 'username_encoded_19', 'username_encoded_20'])\n",
    "tld_columns = pd.DataFrame(categorical_columns['tld_encoded'].values.tolist(), columns=['tld_encoded_1', 'tld_encoded_2', 'tld_encoded_3'])\n",
    "\n",
    "# merge all the columns together\n",
    "X = pd.concat([numeric_columns, hostname_columns, username_columns, tld_columns], axis=1)\n",
    "X.dropna(inplace=True)\n",
    "y = X['free_trial']\n",
    "X.drop(['username','hostname','domain','tld','contact_email', 'group_concat(status_to)', 'free_trial', 'client'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del numeric_columns\n",
    "del categorical_columns\n",
    "del hostname_columns\n",
    "del username_columns\n",
    "del tld_columns\n",
    "\n",
    "# scale the data\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "del scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=47, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X_train and X_test to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# setup to use tensorboard\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=False)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=10, callbacks=[tensorboard])\n",
    "\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
